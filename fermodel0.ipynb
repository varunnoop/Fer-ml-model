{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Constants\nIMG_HEIGHT = 48\nIMG_WIDTH = 48\nBATCH_SIZE = 32\nEPOCHS = 10\nTRAIN_DATA_DIR = '/kaggle/input/fer2013/train'\nVALIDATION_DATA_DIR = '/kaggle/input/fer2013/test'\nCLASS_LABELS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n\n# Datagenerators\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    fill_mode='nearest')\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DATA_DIR,\n    color_mode='grayscale',\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DATA_DIR,\n    color_mode='grayscale',\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True)\n\n\n# Model architecture\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(CLASS_LABELS), activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.save('emotion_detection_model.h5')\nmodel.summary()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the model\nmy_model = load_model('emotion_detection_model.h5')\nfor i in range(test_img.shape[0]):\n    orig_label = CLASS_LABELS[np.argmax(test_lbl[i])]\n    pred_label = CLASS_LABELS[np.argmax(predictions[i])]\n    \n    if orig_label == pred_label:\n        image = test_img[i]\n        plt.imshow(image[:,:,0], cmap='gray')\n        plt.title(\"Original label: \" + orig_label + \", Predicted label: \" + pred_label)\n        plt.show()\n        break \n        \n# Ploting training and validation accuracy\nplt.plot(history.history['accuracy'], label='Training accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Printing the number of trainable parameters in the model\nprint(\"Number of trainable parameters:\", model.count_params())\n#tp-150399\n#acc-0.52-25 epoch","metadata":{},"execution_count":null,"outputs":[]}]}